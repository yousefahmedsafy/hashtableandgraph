{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hashmap\n",
    "A hash table, also known as a hash map, is a data structure used in computer science for efficient data storage and retrieval. It is designed to implement an associative array, where each element (or value) in the array is associated with a unique key. The key-value pairs are stored in such a way that the keys are hashed into numerical values, which are used as indices to access the corresponding values in the array.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49\n"
     ]
    }
   ],
   "source": [
    "grocrsres= {\"egg\":2.44,\"milk\":1.49,\"pear\":0.39}\n",
    "print(grocrsres[\"milk\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binray_search(lst, item):\n",
    "    low=0\n",
    "    high=len(lst)-1\n",
    "    while low<=high:\n",
    "        mid=(low+high)//2\n",
    "        guss=lst[mid]\n",
    "        if guss==item:\n",
    "            return mid\n",
    "        if guss>item:\n",
    "            high=mid-1\n",
    "        else:\n",
    "            low=mid+1\n",
    "    return None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513\n",
      "0.0006635999889113009\n"
     ]
    }
   ],
   "source": [
    "arr1=[i for i in range(10000)]  \n",
    "arr2=[i for i in range(10000)]\n",
    "dict1={i:i for i in range(10000)}\n",
    "# binary search\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "print(binray_search(arr2,513))\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513\n",
      "0.0002696000155992806\n"
     ]
    }
   ],
   "source": [
    "# using hash table\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "print(dict1[513])\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary search requires the dataset to be sorted, while hash tables do not impose any ordering on the keys.\n",
    "Binary search has a time complexity of O(log n) in the average and worst cases, whereas hash table lookups have an average time complexity of O(1) (constant time), assuming a good hash function and minimal collisions.\n",
    "Hash tables are well-suited for dynamic datasets where you need to insert, delete, and update elements frequently. Binary search, on the other hand, is better suited for static, sorted datasets.\n",
    "Binary search is more memory-efficient, as it doesn't require additional memory beyond the input array. Hash tables may consume additional memory for hash table management.\n",
    "In summary, choose binary search when dealing with sorted datasets and you need to locate specific elements efficiently. Choose hash tables (dictionaries) when you need fast access to values using keys and the dataset is not necessarily sorted.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will bring us to … (Collision)\n",
    "while inserting data into the hash map, if the index for the key is already\n",
    "occupied by another data(key-value), a collision arises. A good hash\n",
    "function is such that, it minimizes the chances of collision. <br>\n",
    "# collisions can be avoided by the below methods.\n",
    " ## 1.Separate chaining (open hashing).\n",
    "Chaining: If the hash value (index) of the two keys is the same, the data of\n",
    "the second key is added to the end of the first key in a chain fashion and it\n",
    "goes on. The chaining can be done with help of any other data structures\n",
    "like Linked List, List, or Self Balancing BST (AVL Trees, Red-Black Trees).\n",
    "In chaining, usually, the keys are stored separately outside the hashtable.\n",
    "The access time of keys for the following data structure varies from O(1) to\n",
    "O(n) for Linked List & List and O(logn) for Tree. <br>\n",
    "\n",
    "## 2. Open addressing (closed hashing)\n",
    "If the index is already allocated by another key value, it will probe for the\n",
    "next empty slot in the hash map to allocate the new key value. The probing\n",
    "can be done in different ways.\n",
    "● Linear probing: Searching for the next free slot sequentially from the\n",
    "starting index to the index just before it in a circular manner.\n",
    "- pros: very good cache performance.\n",
    "- cons: primary & secondary clustering will occur.\n",
    "Clustering: The scenario when sequential slots of an index will be\n",
    "allocated very soon for a specific key/Index as the different\n",
    "data(key-value) of the same hash index comes for insertion.\n",
    "● Quadratic probing: Searching for the next free slot in a quadratic\n",
    "manner. for (i²)th slot in ith iteration.\n",
    "- pros: No primary clustering.\n",
    "- cons: secondary clustering will happen, average cache\n",
    "performance.\n",
    "● Double hashing: use a second hash function to find the next free\n",
    "slot on the index that got from the first hash function.\n",
    "- pros: No primary & secondary clustering.\n",
    "- cons: poor cache performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small note :  \n",
    "  dict solve collosion bulit in. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph travsal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the graph implent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque \n",
    "\n",
    "graph={}\n",
    "graph[\"me\"]=[\"alice\",\"bob\" ,\"clalre\"]\n",
    "graph[\"clalre\"]=[\"tom\",\"jonny\"]\n",
    "graph[\"bob\"]=[\"ann\",\"peggy\"]\n",
    "graph[\"alice\"]=[\"peggy\"]\n",
    "graph[\"ann\"]=[]\n",
    "graph[\"tom\"]=[]\n",
    "graph[\"peggy\"]=[]\n",
    "graph[\"jonny\"]=[]\n",
    "search_queue=deque()\n",
    "search_queue+=graph[\"me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth First Search Algorithm (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_is_seller(name):\n",
    "    return name[-1]=='m'\n",
    "\n",
    "def search(name):\n",
    "    search_queue = deque()\n",
    "    search_queue += graph[name]\n",
    "    searched = set()\n",
    "    \n",
    "    while search_queue:\n",
    "        person = search_queue.popleft()\n",
    "        if not person in searched:\n",
    "            if person_is_seller(person):\n",
    "                print(person + \" is a mongo seller!\")\n",
    "                return True\n",
    "            else:\n",
    "                search_queue +=graph[person]\n",
    "                searched.append(person)\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth First Search Algorithm (DFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "C\n",
      "E\n",
      "B\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "def dfs(graph, start):\n",
    "    visited = set()  # To keep track of visited nodes\n",
    "    stack = []  # To store nodes to visit\n",
    "\n",
    "    stack.append(start)  # Start from the initial node\n",
    "\n",
    "    while stack:\n",
    "        vertex = stack.pop()  # Get the last node from the stack\n",
    "\n",
    "        if vertex not in visited:\n",
    "            print(vertex)  # Process the current node\n",
    "            visited.add(vertex)  # Mark it as visited\n",
    "\n",
    "            # Add unvisited neighbors to the stack\n",
    "            stack.extend(neighbor for neighbor in graph[vertex] if neighbor not in visited)\n",
    "\n",
    "# Example graph represented as an adjacency list\n",
    "graph = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['D'],\n",
    "    'C': ['E'],\n",
    "    'D': [],\n",
    "    'E': []\n",
    "}\n",
    "\n",
    "# Start DFS from node 'A'\n",
    "dfs(graph, 'A')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
